{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook assumes you have the DC2 data downloaded  \n",
    "\n",
    "You will have to change directorty paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you need to point to pre-existing scarlet install\n",
    "import sys\n",
    "import deepdisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import scarlet\n",
    "import sep\n",
    "\n",
    "import astropy.io.fits as fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "from scarlet.display import AsinhMapping\n",
    "from astropy.nddata import Cutout2D\n",
    "\n",
    "# Astrodet imports\n",
    "import deepdisc.preprocessing.detection as detection\n",
    "import deepdisc.preprocessing.process as process\n",
    "\n",
    "from deepdisc.astrodet.hsc import get_tract_patch_from_coord, get_hsc_data\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use a better colormap and don't interpolate the pixels\n",
    "matplotlib.rc('image', cmap='gray', interpolation='none', origin='lower')\n",
    "from skimage.util.shape import view_as_blocks\n",
    "from matplotlib import colors\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the versions to test the imports and so we know what works\n",
    "print(scarlet.__version__)\n",
    "print(np.__version__)\n",
    "print(sep.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run Scarlet to produce segmentation maps\n",
    "\n",
    "First, let's test scarlet using one DC2 image. The DC2 image data is divided into \"tracts\" and \"patches\" on the sky. You can get the data here https://data.lsstdesc.org/.\n",
    "\n",
    "You will need to change the directory paths below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdisc.preprocessing.get_data import get_cutout\n",
    "filters = ['u','g','r','i','z','y']\n",
    "dirpath = '/home/g4merz/DC2/coadd-t3828-t3829/deepCoadd-results/'\n",
    "nb=16 #The number of cutouts per side of an image.  4k CCDs are too large to train with, so we reduce the size\n",
    "sp=18 #The \"subpatch\", i.e. which of the nb x nb cutouts to use "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an input catalog\n",
    "\n",
    "The cells below assume you have an input catalog `all_tracts_cat.csv` corresponding to the tracts and patches you've downloaded.  We can run the code without one, but it is necessary for truth-matching any quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.stats import gaussian_fwhm_to_sigma\n",
    "\n",
    "dall=pd.read_csv('/home/g4merz/DC2/nersc_data/data/all_tracts_cat.csv')\n",
    "ra_all = dall['ra'][:].values\n",
    "dec_all = dall['dec'][:].values\n",
    "allcatalog = SkyCoord(ra=ra_all*u.degree, dec=dec_all*u.degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cutout_cat(dirpath,tract,patch,sp,nblocks=4,filters=['u','g','r','i','z','y']):\n",
    "    '''\n",
    "        WARNING!!!!!\n",
    "        It is not efficient to have the full catalog (defined here as dall) as input to a function when doing multiprocesing.  \n",
    "        Keep it in the top level process\n",
    "    \n",
    "    '''\n",
    "    cutout,datsm= get_cutout(dirpath,tract=tract,patch=patch,sp=sp,nblocks=nblocks,filters=filters,plot=False)\n",
    "    xs,ys = cutout.wcs.world_to_pixel(allcatalog)\n",
    "    inds = np.where((xs>=0) & (xs<cutout.shape[1]-1) & (ys>=0) & (ys<cutout.shape[0]-1))[0]\n",
    "    \n",
    "    dcut = dall.iloc[inds]\n",
    "\n",
    "    dcut['new_x'] = xs[inds]\n",
    "    dcut['new_y'] = ys[inds]\n",
    "\n",
    "    column_to_move = dcut.pop(\"objectId\")\n",
    "\n",
    "    # insert column with insert(location, column_name, column_value)\n",
    "    dcut.insert(0, \"objectId\", column_to_move)\n",
    "    dcut.sort_values(by='objectId')\n",
    "    \n",
    "    return datsm, dcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datsm,dcut = get_cutout_cat(dirpath,'3828','1,1',18,nblocks=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(datsm[3],norm=colors.LogNorm(),origin='lower')\n",
    "plt.scatter(dcut['new_x'].values,dcut['new_y'].values,marker='.')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The function below will run scarlet on the input images, and output segmentation maps as well as image fits files for each cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ['u','g','r','i','z','y']\n",
    "\n",
    "\n",
    "def generate_training_data_example(dirpath, tract, patch, sp, outdir, plot_image=False, plot_stretch_Q=False, plot_scene=True,\n",
    "                                   plot_likelihood=False, write_results=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    c : SkyCoord object\n",
    "          The ra, dec pointing (single or lists of pointings)\n",
    "    plot_image : bool\n",
    "          Whether or not to plot the image\n",
    "    plot_stretch_Q : bool\n",
    "          Whether or not to plot different normalizations of your image using the stretch, Q parameters.\n",
    "    plot_scene : bool\n",
    "           Whether or not plot scene with scarlet\n",
    "    plot_likelihood : bool\n",
    "           Whether or not plot the log likelihood of the scarlet fitting\n",
    "    write_results : bool\n",
    "          Whether or not to write results to FITS file\n",
    "    cutout_size : [int, int]\n",
    "          Cutout shape of image\n",
    "          \n",
    "    Returns\n",
    "    -------\n",
    "    The scarlet image test in FITS files.\n",
    "    \n",
    "    \"\"\"\n",
    "    print(tract,patch,sp)\n",
    "    print()\n",
    "    \n",
    "    #datas,dcut = get_cutout_cat(dirpath,tract=tract,patch=patch,sp=sp,nblocks=nb)\n",
    "    #cut = np.where(dcut['mag_i'].values<25.3)[0]\n",
    "    #dcut = dcut.iloc[cut]\n",
    "    \n",
    "    cutout,datas= get_cutout(dirpath,tract=tract,patch=patch,sp=sp,nblocks=nb,filters=filters,plot=False)\n",
    "\n",
    "\n",
    "    ### Run scarlet on image ###\n",
    "\n",
    "    # HSC pixel scale in arcsec/pixel\n",
    "    ps = 0.2\n",
    "    # Approximate PSF size in UD field according to HSC DR2 paper is 0.8 arcsec\n",
    "    sigma_obs = gaussian_fwhm_to_sigma*0.8/ps\n",
    "    \n",
    "    \n",
    "    psf = np.load(f'/home/g4merz/DC2/nersc_data/data/psfs/{tract}_{patch}_0_psfs.npy')\n",
    "    \n",
    "    # Run Scarlet\n",
    "    out = detection.run_scarlet(datas, filters, catalog=None, lvl=2, sigma_model=1, sigma_obs=sigma_obs, psf=psf, plot_scene=plot_scene,\n",
    "                         max_chi2=1000000, morph_thresh=1, stretch=1, Q=5, \n",
    "                         plot_wavelet=False, plot_likelihood=plot_likelihood, plot_sources=False, add_ellipses=False,\n",
    "                         add_labels=False, add_boxes=False, lvl_segmask=1, maskthresh=0.005)\n",
    "\n",
    "    # Unpack output\n",
    "    observation, starlet_sources, model_frame, catalog, catalog_deblended, segmentation_masks = out\n",
    "\n",
    "    \n",
    "    # Save Scarlet data to FITS file\n",
    "    if write_results:\n",
    "        filenames = process.write_scarlet_results(datas, observation, starlet_sources, model_frame, \n",
    "                                             catalog_deblended, segmentation_masks, outdir=outdir, \n",
    "                                             filters=filters, s=f'{tract}_{patch}_{sp}', source_catalog=catalog)\n",
    "    \n",
    "        print(f'\\nSaved scarlet results as {filenames} \\n')\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's run on one cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "outdir='./'\n",
    "\n",
    "generate_training_data_example(tract='3828',patch='1,1',sp=17, dirpath=dirpath,plot_scene=True, plot_likelihood=True, write_results=True, outdir=outdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's run in parallel to speed things up a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "processes = 4\n",
    "\n",
    "tract='3828'\n",
    "sps = (13,17,18,19)\n",
    "patch = '1,1'\n",
    "outdir = './'\n",
    "import multiprocessing\n",
    "from itertools import repeat\n",
    "\n",
    "args = zip(repeat(dirpath),repeat(tract), repeat(patch), sps, repeat(outdir))\n",
    "\n",
    "t0 = time.time()\n",
    "with multiprocessing.Pool(processes=processes) as pool:\n",
    "    results = pool.starmap(generate_training_data_example, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can utilize some preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.deepdisc.data_format.file_io import DDLoader\n",
    "from src.deepdisc.data_format.annotation_functions.annotate_dc2 import annotate_dc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a DDLoader class, which helps gather output files and format them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DDLoader().generate_filedict('./', ['U', 'G', 'R', 'I', 'Z','Y'], '*_scarlet_img.fits', '*_scarlet_segmask.fits')\n",
    "filedict = loader.filedict\n",
    "img_files = np.transpose([filedict[filt][\"img\"] for filt in filedict[\"filters\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we randomly split the datasets into \"train\" and \"test\" directories, with 2 cutouts each.  These new directories are created inside `splitdirs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitdirs = '/home/g4merz/deepdisc/tests/'\n",
    "loader.random_sample(splitdirs,nfiles=[2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a new filedict for the new train directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DDLoader().generate_filedict('/home/g4merz/deepdisc/tests/train/', ['U', 'G', 'R', 'I', 'Z','Y'], '*_scarlet_img.fits', '*_scarlet_segmask.fits')\n",
    "filedict = loader.filedict\n",
    "img_files = np.transpose([filedict[filt][\"img\"] for filt in filedict[\"filters\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a preprocessing function to turn the single-band fits images into a multi-band numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepdisc.preprocessing.process import fits_to_numpy #, fits_to_hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_to_numpy(img_files,'/home/g4merz/deepdisc/tests/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional functionality not covered in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#This is used to create a dataset_dict in the deepdisc format.  It is necessary for training.  \n",
    "#However, the code assumes you have used an input catalog to get ground truth redshifts and object classes, which we have skipped here\n",
    "\n",
    "d='train'\n",
    "dataset_dicts={}\n",
    "dataset_dicts[d] = loader.generate_dataset_dict(annotate_dc2).get_dataset()  \n",
    "\n",
    "\n",
    "#This is used to flatten images for RAIL\n",
    "\n",
    "fits_to_hdf5(img_files,'/home/g4merz/deepdisc/tests/train/',dset='train')\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ddrailnv]",
   "language": "python",
   "name": "conda-env-.conda-ddrailnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
