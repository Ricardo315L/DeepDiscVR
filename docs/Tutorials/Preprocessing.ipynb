{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04413870-779a-4fef-9eaa-76233ccdcbaf",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d325c-1fd1-49ee-a5f0-32c01b0fd1fc",
   "metadata": {},
   "source": [
    "DeepDISC is classified as a supervised deep learning model.  This means that it must have some ground truth information before it can be trained to make new predictions.  \n",
    "\n",
    "Throughout the tutorials, the terms \"ground truth\", \"labels\" and \"annotations\" will be used.  They will be defined here for clarity\n",
    "- Labels: A general term for target information.  The goal of machine learning models is to predict a label y given an input x.  In a supervised context, this is equivalent to finding a mapping function $\\hat{y}$= F(x | y) that minimizes a loss L(y|$\\hat{y}$)\n",
    "- Ground truth: A set of target information (labels) that is already known prior to training.  This is used to minimize the loss function\n",
    "- Annotations: Detectron2 terminology for labels.  Annotations consist of object locations, footprints, and classes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fdd39e-0bc8-40af-b317-dbc4675b1813",
   "metadata": {},
   "source": [
    "In order to train DeepDISC, we need to produce ground truth labels for our input data. The goal of DeepDISC is to predict object $\\textit{locations}$, $\\textit{masks}$, and $\\textit{classes}$, so we need this information beforehand for our training.\n",
    "\n",
    "\n",
    "There are a few options for preprocessing images to produce labels in the ```preprocessing``` module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef73183e-4844-49af-bff6-85f72bf8af20",
   "metadata": {},
   "source": [
    "### No input catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea5fca-a46d-476d-ba5e-e307ab4e6d53",
   "metadata": {},
   "source": [
    "If all you have are images, then not to worry! Object locations and masks can still be produced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d12265-ca50-49c5-8289-a2aea66e72fb",
   "metadata": {},
   "source": [
    "The object detection and mask production are done with ```sep``` and ```scarlet```, standard codes for astronmical image processing. To produce labels for an image, use ```deepdisc.preprocessing.detection.run_scarlet```.  The main inputs you will need are an image, a list of filters, and a psf (either an image or a gaussian standard deviation).\n",
    "Check the API documentation for details. \n",
    "\n",
    "This will produce a few intermediate objects that contain all of the relevant information.  However, we format them into FITS files for ease of access.  This is done using ```deeepdisc.preprocess.process.write_scarlet_results```\n",
    "\n",
    "\n",
    "(datas, observation, starlet_sources, model_frame, \n",
    "                                             segmentation_masks, outdir=outdir, \n",
    "                                             filters=filters, s=f'{tract}_{patch}_{sp}', source_catalog=catalog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14280e6-edaa-41f9-8d8c-6f8647760e88",
   "metadata": {},
   "source": [
    "### Input catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d629d-97fe-4d4e-b78f-e7a5f1ee0c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
